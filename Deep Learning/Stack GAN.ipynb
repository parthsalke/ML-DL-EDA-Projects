{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, ReLU, Activation\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Concatenate, Dense, concatenate\n",
    "from tensorflow.keras.layers import Flatten, Lambda, Reshape, ZeroPadding2D, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Argument Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditioned by the text.\n",
    "def conditioning_augmentation(x):\n",
    "    mean = x[:, :128]\n",
    "    log_sigma = x[:, 128:]\n",
    "    stddev = tf.math.exp(log_sigma)\n",
    "    epsilon = K.random_normal(shape=K.constant((mean.shape[1], ), dtype='int32')) \n",
    "    c = mean + stddev * epsilon\n",
    "    return c\n",
    "\n",
    "def build_ca_network():\n",
    "    #Builds the conditioning augmentation network.\n",
    "    input_layer1 = Input(shape=(1024,)) #size of the vocabulary in the text data\n",
    "    mls = Dense(256)(input_layer1)\n",
    "    mls = LeakyReLU(alpha=0.2)(mls)\n",
    "    ca = Lambda(conditioning_augmentation)(mls)\n",
    "    return Model(inputs=[input_layer1], outputs=[ca]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling and Stage 1 Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpSamplingBlock(x, num_kernels):\n",
    "\t\"\"\"An Upsample block with Upsampling2D, Conv2D, BatchNormalization and a ReLU activation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx: The preceding layer as input.\n",
    "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
    "\n",
    "\tReturns:\n",
    "\t\tx: The final activation layer after the Upsampling block.\n",
    "\t\"\"\"\n",
    "\tx = UpSampling2D(size=(2,2))(x)\n",
    "\tx = Conv2D(num_kernels, kernel_size=(3,3), padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x) #prevent from mode collapse\n",
    "\tx = ReLU()(x)\n",
    "\treturn x\n",
    "\n",
    "\n",
    "def build_stage1_generator():\n",
    "\n",
    "\tinput_layer1 = Input(shape=(1024,))\n",
    "\tca = Dense(256)(input_layer1)\n",
    "\tca = LeakyReLU(alpha=0.2)(ca)\n",
    "\n",
    "\t# Obtain the conditioned text\n",
    "\tc = Lambda(conditioning_augmentation)(ca)\n",
    "\n",
    "\tinput_layer2 = Input(shape=(100,))\n",
    "\tconcat = Concatenate(axis=1)([c, input_layer2]) \n",
    "\n",
    "\tx = Dense(16384, use_bias=False)(concat) \n",
    "\tx = ReLU()(x)\n",
    "\tx = Reshape((4, 4, 1024), input_shape=(16384,))(x)\n",
    "\n",
    "\tx = UpSamplingBlock(x, 512) \n",
    "\tx = UpSamplingBlock(x, 256)\n",
    "\tx = UpSamplingBlock(x, 128)\n",
    "\tx = UpSamplingBlock(x, 64)   # upsampled our image to 64*64*3 \n",
    "\n",
    "\tx = Conv2D(3, kernel_size=3, padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = Activation('tanh')(x)\n",
    "\n",
    "\tstage1_gen = Model(inputs=[input_layer1, input_layer2], outputs=[x, ca]) \n",
    "\treturn stage1_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1024)]       0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          262400      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 128)          0           ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 228)          0           ['lambda[0][0]',                 \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16384)        3735552     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 16384)        0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 4, 4, 1024)   0           ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 8, 8, 1024)   0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 8, 8, 512)    4718592     ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 8, 8, 512)   2048        ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 8, 8, 512)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 512)  0          ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 16, 256)  1179648     ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 16, 16, 256)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 256)  0          ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 128)  294912      ['up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 128)  0          ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 64)   73728       ['up_sampling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 3)    1728        ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 64, 64, 3)    0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,270,400\n",
      "Trainable params: 10,268,480\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_stage1_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(x, num_kernels, kernel_size=(4,4), strides=2, activation=True):\n",
    "\t\"\"\"A ConvBlock with a Conv2D, BatchNormalization and LeakyReLU activation.\n",
    "\n",
    "\tArgs:\n",
    "\t\tx: The preceding layer as input.\n",
    "\t\tnum_kernels: Number of kernels for the Conv2D layer.\n",
    "\n",
    "\tReturns:\n",
    "\t\tx: The final activation layer after the ConvBlock block.\n",
    "\t\"\"\"\n",
    "\tx = Conv2D(num_kernels, kernel_size=kernel_size, padding='same', strides=strides, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(x)\n",
    "\tx = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\t\n",
    "\tif activation:\n",
    "\t\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\treturn x\n",
    "\n",
    "\n",
    "def build_embedding_compressor():\n",
    "    \"\"\"Build embedding compressor model\n",
    "    \"\"\"\n",
    "    input_layer1 = Input(shape=(1024,)) \n",
    "    x = Dense(128)(input_layer1)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    model = Model(inputs=[input_layer1], outputs=[x])\n",
    "    return model\n",
    "\n",
    "# the discriminator is fed with two inputs, the feature from Generator and the text embedding\n",
    "def build_stage1_discriminator():\n",
    "\t\"\"\"Builds the Stage 1 Discriminator that uses the 64x64 resolution images from the generator\n",
    "\tand the compressed and spatially replicated embedding.\n",
    "\n",
    "\tReturns:\n",
    "\t\tStage 1 Discriminator Model for StackGAN.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(64, 64, 3))  \n",
    "\n",
    "\tx = Conv2D(64, kernel_size=(4,4), strides=2, padding='same', use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(input_layer1)\n",
    "\tx = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\tx = ConvBlock(x, 128)\n",
    "\tx = ConvBlock(x, 256)\n",
    "\tx = ConvBlock(x, 512)\n",
    "\n",
    "\t# Obtain the compressed and spatially replicated text embedding\n",
    "\tinput_layer2 = Input(shape=(4, 4, 128)) #2nd input to discriminator, text embedding\n",
    "\tconcat = concatenate([x, input_layer2])\n",
    "\n",
    "\tx1 = Conv2D(512, kernel_size=(1,1), padding='same', strides=1, use_bias=False,\n",
    "\t\t\t\tkernel_initializer='he_uniform')(concat)\n",
    "\tx1 = BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
    "\tx1 = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\t# Flatten and add a FC layer to predict.\n",
    "\tx1 = Flatten()(x1)\n",
    "\tx1 = Dense(1)(x1)\n",
    "\tx1 = Activation('sigmoid')(x1)\n",
    "\n",
    "\tstage1_dis = Model(inputs=[input_layer1, input_layer2], outputs=[x1])  \n",
    "\treturn stage1_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 64)   3072        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 64)   0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 128)  131072      ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 16, 16, 128)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 256)    524288      ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 8, 8, 256)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 4, 4, 512)    2097152     ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 4, 4, 512)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 4, 4, 512)    0           ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8192)         0           ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            8193        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 4, 4, 128)]  0           []                               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 1)            0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,767,361\n",
      "Trainable params: 2,765,569\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_stage1_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 GAN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building GAN with Generator and Discriminator\n",
    "\n",
    "def build_adversarial(generator_model, discriminator_model):\n",
    "\t\"\"\"Stage 1 Adversarial model.\n",
    "\n",
    "\tArgs:\n",
    "\t\tgenerator_model: Stage 1 Generator Model\n",
    "\t\tdiscriminator_model: Stage 1 Discriminator Model\n",
    "\n",
    "\tReturns:\n",
    "\t\tAdversarial Model.\n",
    "\t\"\"\"\n",
    "\tinput_layer1 = Input(shape=(1024,))  \n",
    "\tinput_layer2 = Input(shape=(100,)) \n",
    "\tinput_layer3 = Input(shape=(4, 4, 128)) \n",
    "\n",
    "\tx, ca = generator_model([input_layer1, input_layer2]) #text,noise\n",
    "\n",
    "\tdiscriminator_model.trainable = False \n",
    "\n",
    "\tprobabilities = discriminator_model([x, input_layer3]) \n",
    "\tadversarial_model = Model(inputs=[input_layer1, input_layer2, input_layer3], outputs=[probabilities, ca])\n",
    "\treturn adversarial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 1024)]       0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             [(None, 64, 64, 3),  10270400    ['input_5[0][0]',                \n",
      "                                 (None, 256)]                     'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 4, 4, 128)]  0           []                               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 1)            2767361     ['model[0][0]',                  \n",
      "                                                                  'input_7[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,037,761\n",
      "Trainable params: 10,268,480\n",
      "Non-trainable params: 2,769,281\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ganstage1 = build_adversarial(generator, discriminator)\n",
    "ganstage1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Utlities and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_prefix():\n",
    "\tcheckpoint_dir = './training_checkpoints'\n",
    "\tcheckpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "\n",
    "\treturn checkpoint_prefix\n",
    "\n",
    "def adversarial_loss(y_true, y_pred):\n",
    "\tmean = y_pred[:, :128]\n",
    "\tls = y_pred[:, 128:]\n",
    "\tloss = -ls + 0.5 * (-1 + tf.math.exp(2.0 * ls) + tf.math.square(mean))\n",
    "\tloss = K.mean(loss)\n",
    "\treturn loss\n",
    "\n",
    "def normalize(input_image, real_image):\n",
    "\tinput_image = (input_image / 127.5) - 1\n",
    "\treal_image = (real_image / 127.5) - 1\n",
    "\n",
    "\treturn input_image, real_image\n",
    "\n",
    "def load_class_ids_filenames(class_id_path, filename_path):\n",
    "\twith open(class_id_path, 'rb') as file:\n",
    "\t\tclass_id = pickle.load(file, encoding='latin1')\n",
    "\n",
    "\twith open(filename_path, 'rb') as file:\n",
    "\t\tfilename = pickle.load(file, encoding='latin1')\n",
    "\n",
    "\treturn class_id, filename\n",
    "\n",
    "def load_text_embeddings(text_embeddings):\n",
    "\twith open(text_embeddings, 'rb') as file:\n",
    "\t\tembeds = pickle.load(file, encoding='latin1')\n",
    "\t\tembeds = np.array(embeds)\n",
    "\n",
    "\treturn embeds\n",
    "\n",
    "def load_bbox(data_path):\n",
    "\tbbox_path = data_path + '/bounding_boxes.txt'\n",
    "\timage_path = data_path + '/images.txt'\n",
    "\tbbox_df = pd.read_csv(bbox_path, delim_whitespace=True, header=None).astype(int)\n",
    "\tfilename_df = pd.read_csv(image_path, delim_whitespace=True, header=None)\n",
    "\n",
    "\tfilenames = filename_df[1].tolist()\n",
    "\tbbox_dict = {i[:-4]:[] for i in filenames[:2]}\n",
    "\n",
    "\tfor i in range(0, len(filenames)):\n",
    "\t\tbbox = bbox_df.iloc[i][1:].tolist()\n",
    "\t\tdict_key = filenames[i][:-4]\n",
    "\t\tbbox_dict[dict_key] = bbox\n",
    "\n",
    "\treturn bbox_dict\n",
    "\n",
    "def load_images(image_path, bounding_box, size):\n",
    "\t\"\"\"Crops the image to the bounding box and then resizes it.\n",
    "\t\"\"\"\n",
    "\timage = Image.open(image_path).convert('RGB')\n",
    "\tw, h = image.size\n",
    "\tif bounding_box is not None:\n",
    "\t\tr = int(np.maximum(bounding_box[2], bounding_box[3]) * 0.75)\n",
    "\t\tc_x = int((bounding_box[0] + bounding_box[2]) / 2)\n",
    "\t\tc_y = int((bounding_box[1] + bounding_box[3]) / 2)\n",
    "\t\ty1 = np.maximum(0, c_y - r)\n",
    "\t\ty2 = np.minimum(h, c_y + r)\n",
    "\t\tx1 = np.maximum(0, c_x - r)\n",
    "\t\tx2 = np.minimum(w, c_x + r)\n",
    "\t\timage = image.crop([x1, y1, x2, y2])\n",
    "\n",
    "\timage = image.resize(size, PIL.Image.BILINEAR)\n",
    "\treturn image\n",
    "\n",
    "def load_data(filename_path, class_id_path, dataset_path, embeddings_path, size):\n",
    "\t\"\"\"Loads the Dataset.\n",
    "\t\"\"\"\n",
    "\tdata_dir = \"D:/GAN- Birds/birds\"\n",
    "\ttrain_dir = data_dir + \"/train\"\n",
    "\ttest_dir = data_dir + \"/test\"\n",
    "\tembeddings_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\tembeddings_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "\tfilename_path_train = train_dir + \"/filenames.pickle\"\n",
    "\tfilename_path_test = test_dir + \"/filenames.pickle\"\n",
    "\tclass_id_path_train = train_dir + \"/class_info.pickle\"\n",
    "\tclass_id_path_test = test_dir + \"/class_info.pickle\"\n",
    "\tdataset_path = \"D:/GAN- Birds/CUB_200_2011\"\n",
    "\tclass_id, filenames = load_class_ids_filenames(class_id_path, filename_path)\n",
    "\tembeddings = load_text_embeddings(embeddings_path)\n",
    "\tbbox_dict = load_bbox(dataset_path)\n",
    "\n",
    "\tx, y, embeds = [], [], []\n",
    "\n",
    "\tfor i, filename in enumerate(filenames):\n",
    "\t\tbbox = bbox_dict[filename]\n",
    "\n",
    "\t\ttry:\t\n",
    "\t\t\timage_path = f'{dataset_path}/images/{filename}.jpg'\n",
    "\t\t\timage = load_images(image_path, bbox, size)\n",
    "\t\t\te = embeddings[i, :, :]\n",
    "\t\t\tembed_index = np.random.randint(0, e.shape[0] - 1)\n",
    "\t\t\tembed = e[embed_index, :]\n",
    "\n",
    "\t\t\tx.append(np.array(image))\n",
    "\t\t\ty.append(class_id[i])\n",
    "\t\t\tembeds.append(embed)\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f'{e}')\n",
    "\t\n",
    "\tx = np.array(x)\n",
    "\ty = np.array(y)\n",
    "\tembeds = np.array(embeds)\n",
    "\t\n",
    "\treturn x, y, embeds\n",
    "\n",
    "def save_image(file, save_path):\n",
    "\t#Saves the image at the specified file path.\n",
    "\timage = plt.figure()\n",
    "\tax = image.add_subplot(1,1,1)\n",
    "\tax.imshow(file)\n",
    "\tax.axis(\"off\")\n",
    "\tplt.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m64\u001b[0m\n\u001b[1;33m    real = np.ones((self.batch_size, 1), dtype='float') * 0.9\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class StackGanStage1(object):\n",
    "    \"\"\"StackGAN Stage 1 class.\"\"\"\n",
    "\n",
    "    data_dir = \"D:/GAN- Birds/birds\"\n",
    "    train_dir = data_dir + \"/train\"\n",
    "    test_dir = data_dir + \"/test\"\n",
    "    embeddings_path_train = train_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "    embeddings_path_test = test_dir + \"/char-CNN-RNN-embeddings.pickle\"\n",
    "    filename_path_train = train_dir + \"/filenames.pickle\"\n",
    "    filename_path_test = test_dir + \"/filenames.pickle\"\n",
    "    class_id_path_train = train_dir + \"/class_info.pickle\"\n",
    "    class_id_path_test = test_dir + \"/class_info.pickle\"\n",
    "    dataset_path = \"D:/GAN- Birds/CUB_200_2011\"\n",
    "    def __init__(self, epochs=500, z_dim=100, batch_size=64, enable_function=True, stage1_generator_lr=0.0002, stage1_discriminator_lr=0.0002):\n",
    "\t    self.epochs = epochs\n",
    "\t    self.z_dim = z_dim\n",
    "\t    self.enable_function = enable_function\n",
    "\t    self.stage1_generator_lr = stage1_generator_lr\n",
    "\t    self.stage1_discriminator_lr = stage1_discriminator_lr\n",
    "\t    self.image_size = 64\n",
    "\t    self.conditioning_dim = 128\n",
    "\t    self.batch_size = batch_size\n",
    "        \n",
    "\t    self.stage1_generator_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)\n",
    "\t    self.stage1_discriminator_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
    "        \n",
    "\t    self.stage1_generator = build_stage1_generator()\n",
    "\t    self.stage1_generator.compile(loss='mse', optimizer=self.stage1_generator_optimizer)\n",
    "\n",
    "\t    self.stage1_discriminator = build_stage1_discriminator()\n",
    "\t    self.stage1_discriminator.compile(loss='binary_crossentropy', optimizer=self.stage1_discriminator_optimizer)\n",
    "\n",
    "\t    self.ca_network = build_ca_network()\n",
    "\t    self.ca_network.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "\t    self.embedding_compressor = build_embedding_compressor()\n",
    "\t    self.embedding_compressor.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "\t    self.stage1_adversarial = build_adversarial(self.stage1_generator, self.stage1_discriminator)\n",
    "\t    self.stage1_adversarial.compile(loss=['binary_crossentropy', adversarial_loss], loss_weights=[1, 2.0], optimizer=self.stage1_generator_optimizer)\n",
    "\n",
    "\t    self.checkpoint1 = tf.train.Checkpoint(\n",
    "        \tgenerator_optimizer=self.stage1_generator_optimizer,\n",
    "        \tdiscriminator_optimizer=self.stage1_discriminator_optimizer,\n",
    "        \tgenerator=self.stage1_generator,\n",
    "        \tdiscriminator=self.stage1_discriminator)\n",
    "\n",
    "    def visualize_stage1(self):\n",
    "        #Running Tensorboard visualizations.\n",
    "\t    tb = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "\t    tb.set_model(self.stage1_generator)\n",
    "\t    tb.set_model(self.stage1_discriminator)\n",
    "\t    tb.set_model(self.ca_network)\n",
    "\t    tb.set_model(self.embedding_compressor)\n",
    "\n",
    "    def train_stage1(self):\n",
    "        #Trains the stage1 StackGAN.\n",
    "\t    x_train, y_train, train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n",
    "                                    dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(64, 64))\n",
    "\n",
    "\t    x_test, y_test, test_embeds = load_data(filename_path=filename_path_test, class_id_path=class_id_path_test, \n",
    "        dataset_path=dataset_path, embeddings_path=embeddings_path_test, size=(64, 64))\n",
    "        \n",
    "        real = np.ones((self.batch_size, 1), dtype='float') * 0.9\n",
    "        fake = np.zeros((self.batch_size, 1), dtype='float') * 0.1\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            print(f'Epoch: {epoch}')\n",
    "\n",
    "            gen_loss = []\n",
    "            dis_loss = []\n",
    "\n",
    "            num_batches = int(x_train.shape[0] / self.batch_size)\n",
    "            \n",
    "            for i in range(num_batches):\n",
    "                latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t        embedding_text = train_embeds[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\t\t        compressed_embedding = self.embedding_compressor.predict_on_batch(embedding_text)\n",
    "\t\t        compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, 128))\n",
    "\t\t        compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))\n",
    "\n",
    "\t\t        image_batch = x_train[i * self.batch_size:(i+1) * self.batch_size]\n",
    "\t\t        image_batch = (image_batch - 127.5) / 127.5\n",
    "\n",
    "\t\t        gen_images, _ = self.stage1_generator.predict([embedding_text, latent_space])\n",
    "\n",
    "\t\t        discriminator_loss = self.stage1_discriminator.train_on_batch([image_batch, compressed_embedding], \n",
    "\t\t\t\t\tnp.reshape(real, (self.batch_size, 1)))\n",
    "\n",
    "\t\t        discriminator_loss_gen = self.stage1_discriminator.train_on_batch([gen_images, compressed_embedding],\n",
    "\t\t\t\t\tnp.reshape(fake, (self.batch_size, 1)))\n",
    "\n",
    "\t\t        discriminator_loss_wrong = self.stage1_discriminator.train_on_batch([gen_images[: self.batch_size-1], compressed_embedding[1:]], \n",
    "\t\t\t\t\tnp.reshape(fake[1:], (self.batch_size-1, 1)))\n",
    "\n",
    "\t\t        # Discriminator loss\n",
    "\t\t        d_loss = 0.5 * np.add(discriminator_loss, 0.5 * np.add(discriminator_loss_gen, discriminator_loss_wrong))\n",
    "\t\t        dis_loss.append(d_loss)\n",
    "\n",
    "\t\t        print(f'Discriminator Loss: {d_loss}')\n",
    "\n",
    "\t\t        # Generator loss\n",
    "\t\t        g_loss = self.stage1_adversarial.train_on_batch([embedding_text, latent_space, compressed_embedding],\n",
    "\t\t\t\t\t[K.ones((self.batch_size, 1)) * 0.9, K.ones((self.batch_size, 256)) * 0.9])\n",
    "\n",
    "\t\t        print(f'Generator Loss: {g_loss}')\n",
    "\t\t        gen_loss.append(g_loss)\n",
    "                \n",
    "                if epoch % 5 == 0:\n",
    "                    latent_space = np.random.normal(0, 1, size=(self.batch_size, self.z_dim))\n",
    "\t\t\t\t    embedding_batch = test_embeds[0 : self.batch_size]\n",
    "\t\t\t\t    gen_images, _ = self.stage1_generator.predict_on_batch([embedding_batch, latent_space])\n",
    "                    \n",
    "                    for i, image in enumerate(gen_images[:10]):\n",
    "                        save_image(image, f'test/gen_1_{epoch}_{i}')\n",
    "\n",
    "\t\t        if epoch % 25 == 0:\n",
    "                    self.stage1_generator.save_weights('weights/stage1_gen.h5')\n",
    "\t\t            self.stage1_discriminator.save_weights(\"weights/stage1_disc.h5\")\n",
    "\t\t            self.ca_network.save_weights('weights/stage1_ca.h5')\n",
    "\t\t            self.embedding_compressor.save_weights('weights/stage1_embco.h5')\n",
    "\t\t            self.stage1_adversarial.save_weights('weights/stage1_adv.h5')      \n",
    "\n",
    "\t    self.stage1_generator.save_weights('weights/stage1_gen.h5')\n",
    "\t    self.stage1_discriminator.save_weights(\"weights/stage1_disc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename_path_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-10b8f6865124>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstage1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mStackGanStage1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstage1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_stage1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-69d0e73e5be6>\u001b[0m in \u001b[0;36mtrain_stage1\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m \t  \"\"\"Trains the stage1 StackGAN.\n\u001b[0;32m     59\u001b[0m     \"\"\"\n\u001b[1;32m---> 60\u001b[1;33m \t  x_train, y_train, train_embeds = load_data(filename_path=filename_path_train, class_id_path=class_id_path_train,\n\u001b[0m\u001b[0;32m     61\u001b[0m       dataset_path=dataset_path, embeddings_path=embeddings_path_train, size=(64, 64))\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filename_path_train' is not defined"
     ]
    }
   ],
   "source": [
    "stage1= StackGanStage1()\n",
    "stage1.train_stage1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
